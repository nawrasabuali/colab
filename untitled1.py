# -*- coding: utf-8 -*-
"""untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/nawrasabuali/8f88acdfd6ee58463765a24dccc8898f/untitled1.ipynb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model

# Set the image size, batch size, and number of features.
IMG_SIZE = 224
BATCH_SIZE = 64
NUM_CLASSES = 5
EPOCHS = 100
NUM_FEATURES = 2048

# Create an instance of the ResNet50 model.
feature_extractor = ResNet50(
    weights="imagenet", include_top=False, pooling="avg", input_shape=(IMG_SIZE, IMG_SIZE, 3)
)

# Define the data augmentation pipeline.
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Load the training data.
train_generator = train_datagen.flow_from_directory(
    '/content/data/train',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True
)

# Load the testing data.
test_generator = test_datagen.flow_from_directory(
    '/content/data/test',
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
print(class_names)

# Get the number of classes from the generator
num_classes = len(train_generator.class_indices)
print(num_classes)

IMG_SIZE = 224
NUM_CLASSES = 5
NUM_FEATURES = 2048
EPOCHS = 100
# Load train and test data
train_data = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/data/train",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)
test_data = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/data/test",
    image_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE
)

# Preprocess the train and test data
# Preprocess the train and test data
train_data = train_data.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), tf.one_hot(y, num_classes)))
test_data = test_data.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), tf.one_hot(y, num_classes)))

# Load the pre-trained ResNet50 model and add a new output layer
base_model = ResNet50(
    weights="imagenet", include_top=False, pooling="avg", input_shape=(IMG_SIZE, IMG_SIZE, 3)
)

x = base_model.output
x = Dense(num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=x)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_data, epochs=EPOCHS)

# Evaluate the model on the test data
loss, accuracy = model.evaluate(test_data)
print("Test accuracy:", accuracy)